from fastapi import FastAPI
from gensim.models import KeyedVectors
import numpy as np
import uvicorn

app = FastAPI()

# NaÄtenÃ­ modelu Google News Word2Vec
try:
    print("â³ NaÄÃ­tÃ¡nÃ­ modelu...")
    model = KeyedVectors.load_word2vec_format("GoogleNews-vectors-negative300.bin.gz", binary=True)
    print("âœ… Model naÄten!")
except Exception as e:
    print(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ modelu: {e}")
    model = None


def get_sentence_vector(sentence: str):
    """ VypoÄÃ­tÃ¡ prÅ¯mÄ›rnÃ½ vektor vÄ›ty. """
    words = sentence.split()
    word_vectors = [model[word] for word in words if word in model]
    if not word_vectors:
        return None  # Å½Ã¡dnÃ© pouÅ¾itelnÃ© vektory
    return np.mean(word_vectors, axis=0)  # PrÅ¯mÄ›rnÃ½ vektor


@app.get("/word2vec")
async def get_similar_words(word: str, topn: int = 3):
    try:
        if not model:
            print("âŒ Word2Vec model nebyl ÃºspÄ›Å¡nÄ› naÄten.")
            return {"error": "Word2Vec model nebyl ÃºspÄ›Å¡nÄ› naÄten."}

        print(f"ğŸ“¥ PÅ™ijatÃ½ poÅ¾adavek: word={word}")

        sentence_vector = get_sentence_vector(word)
        if sentence_vector is None:
            print("âŒ Slovo nenÃ­ v modelu Word2Vec.")
            return {"error": "Slovo nenÃ­ v modelu Word2Vec."}

        similar_words = model.similar_by_vector(sentence_vector, topn=topn)
        suggestions = [w[0] for w in similar_words]
        probabilities = [f"{s * 100:.2f}%" for _, s in similar_words]

        print("ğŸ” PodobnÃ¡ slova:")
        for word, prob in zip(suggestions, probabilities):
            print(f"{word}: {prob}")

    except Exception as e:
        print(f"âŒ Chyba: {e}")
        return {"error": str(e)}

    return {"word": word, "suggestions": suggestions}  # PravdÄ›podobnosti se nevracÃ­, pouze vypisujÃ­


if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=5000)
